{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verified-preliminary",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-sweden",
   "metadata": {},
   "source": [
    "## Load data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liberal-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executed-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "X_train = np.load(\"data/train_pixels.npy\") \n",
    "X_trainLAND = np.load(\"data/train_landmarks.npy\")\n",
    "y_train = np.load(\"data/train_labels.npy\")\n",
    "    \n",
    "# Public Test Data - Used to Validate Training\n",
    "X_test = np.load(\"data/eval_pixels.npy\")\n",
    "X_testLAND = np.load(\"data/eval_landmarks.npy\")\n",
    "y_test = np.load(\"data/eval_labels.npy\")\n",
    "\n",
    "# Private Test Data - Used for Final Prediction\n",
    "X_final = np.load(\"data/test_pixels.npy\")\n",
    "X_finalLAND = np.load(\"data/test_landmarks.npy\")\n",
    "y_final = np.load(\"data/test_labels.npy\")\n",
    "\n",
    "# Emotions\n",
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "boring-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainSVM = X_train.reshape(-1, 48*48)\n",
    "X_testSVM = X_test.reshape(-1, 48*48)\n",
    "X_finalSVM = X_final.reshape(-1, 48*48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-permit",
   "metadata": {},
   "source": [
    "## Base Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-sunday",
   "metadata": {},
   "source": [
    "### Model 1 - SVM with Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "english-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 110 was determined during tuning\n",
    "n_components = 110\n",
    "pca1 = RandomizedPCA(n_components=n_components, whiten=True, random_state=42).fit(X_trainSVM)\n",
    "\n",
    "X_train_pca1 = pca1.transform(X_trainSVM)\n",
    "X_test_pca1 = pca1.transform(X_testSVM)\n",
    "X_final_pca1 = pca1.transform(X_finalSVM)\n",
    "\n",
    "SVM1 = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "SVM1 = SVM1.fit(X_train_pca1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-correspondence",
   "metadata": {},
   "source": [
    "### Model 2 - SVM with Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prostate-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80 was determined during tuning\n",
    "n_components = 80\n",
    "pca2 = RandomizedPCA(n_components=n_components, whiten=True, random_state=42).fit(X_trainLAND)\n",
    "\n",
    "X_train_pca2 = pca2.transform(X_trainLAND)\n",
    "X_test_pca2 = pca2.transform(X_testLAND)\n",
    "X_final_pca2 = pca2.transform(X_finalLAND)\n",
    "\n",
    "SVM2 = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "SVM2 = SVM2.fit(X_train_pca2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-disclaimer",
   "metadata": {},
   "source": [
    "### Model 3 - XGBoost with Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confidential-tiger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_class=7, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB1 = XGBClassifier(objective='multi:softprob', \n",
    "                         num_class= len(emotions), \n",
    "                         use_label_encoder=False,\n",
    "                         eval_metric='mlogloss')\n",
    "\n",
    "print(\"fitting\")\n",
    "XGB1.fit(X_trainSVM, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-tissue",
   "metadata": {},
   "source": [
    "### Model 4 - XGBoost with Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atlantic-watson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_class=7, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB2 = XGBClassifier(objective='multi:softprob', \n",
    "                         num_class= len(emotions), \n",
    "                         use_label_encoder=False,\n",
    "                         eval_metric='mlogloss')\n",
    "\n",
    "print(\"fitting\")\n",
    "XGB2.fit(X_trainLAND, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-porcelain",
   "metadata": {},
   "source": [
    "## Ensemble Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-welding",
   "metadata": {},
   "source": [
    "### Soft Voting\n",
    "Here we take the probability distribution of the predictions and sum them over all predictions.  Then we take the argmax as the final predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "devoted-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_vote(p1, p2, p3, p4):\n",
    "    total = p1 + p2 + p3 + p4\n",
    "    \n",
    "    return np.argmax(total, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nasty-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = SVM1.predict_proba(X_test_pca1)\n",
    "pred2 = SVM2.predict_proba(X_test_pca2)\n",
    "pred3 = XGB1.predict_proba(X_testSVM)\n",
    "pred4 = XGB2.predict_proba(X_testLAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sticky-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_pred = soft_vote(pred1, pred2, pred3, pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "received-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6322095291167457\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, sv_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-video",
   "metadata": {},
   "source": [
    "### Hard Voting\n",
    "Here we take the majority vote from each models final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "frank-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "      \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    "  \n",
    "    return num\n",
    "\n",
    "def maj_vote(p1, p2, p3, p4):\n",
    "    final_pred = []\n",
    "    \n",
    "    for i in range(len(X_testLAND)):\n",
    "        tmp = [p1[i], p2[i], p3[i], p4[i]]\n",
    "        final_pred.append(most_frequent(tmp))\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aerial-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1b = SVM1.predict(X_test_pca1)\n",
    "pred2b = SVM2.predict(X_test_pca2)\n",
    "pred3b = XGB1.predict(X_testSVM)\n",
    "pred4b = XGB2.predict(X_testLAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_pred = maj_vote(pred1b, pred2b, pred3b, pred4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tamil-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6341599331290053\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, hv_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-village",
   "metadata": {},
   "source": [
    "## Final Ensemble Prediction\n",
    "Here we use the private evaluation dataset and make our final prediction with our best ensemble (Hard Voting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "utility-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1final = SVM1.predict(X_final_pca1)\n",
    "pred2final = SVM2.predict(X_final_pca2)\n",
    "pred3final = XGB1.predict(X_finalSVM)\n",
    "pred4final = XGB2.predict(X_finalLAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "architectural-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = maj_vote(pred1final, pred2final, pred3final, pred4final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comparable-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6182780718863193\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_final, final_pred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
