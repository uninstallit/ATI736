{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anonymous-dependence",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-stock",
   "metadata": {},
   "source": [
    "## Load data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metallic-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apparent-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "X_train = np.load(\"data/train_pixels.npy\") \n",
    "X_trainLAND = np.load(\"data/train_landmarks.npy\")\n",
    "y_train = np.load(\"data/train_labels.npy\")\n",
    "    \n",
    "# Public Test Data - Used to Validate Training\n",
    "X_test = np.load(\"data/eval_pixels.npy\")\n",
    "X_testLAND = np.load(\"data/eval_landmarks.npy\")\n",
    "y_test = np.load(\"data/eval_labels.npy\")\n",
    "\n",
    "# Private Test Data - Used for Final Prediction\n",
    "X_final = np.load(\"data/test_pixels.npy\")\n",
    "X_finalLAND = np.load(\"data/test_landmarks.npy\")\n",
    "y_final = np.load(\"data/test_labels.npy\")\n",
    "\n",
    "# Emotions\n",
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loving-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainSVM = X_train.reshape(-1, 48*48)\n",
    "X_testSVM = X_test.reshape(-1, 48*48)\n",
    "X_finalSVM = X_final.reshape(-1, 48*48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-vault",
   "metadata": {},
   "source": [
    "## Base Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-management",
   "metadata": {},
   "source": [
    "### Model 1 - SVM with Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mature-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 110 was determined during tuning\n",
    "n_components = 110\n",
    "pca1 = RandomizedPCA(n_components=n_components, whiten=True, random_state=42).fit(X_trainSVM)\n",
    "\n",
    "X_train_pca1 = pca1.transform(X_trainSVM)\n",
    "X_test_pca1 = pca1.transform(X_testSVM)\n",
    "X_final_pca1 = pca1.transform(X_finalSVM)\n",
    "\n",
    "SVM1 = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "SVM1 = SVM1.fit(X_train_pca1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-intake",
   "metadata": {},
   "source": [
    "### Model 2 - SVM with Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "still-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80 was determined during tuning\n",
    "n_components = 80\n",
    "pca2 = RandomizedPCA(n_components=n_components, whiten=True, random_state=42).fit(X_trainLAND)\n",
    "\n",
    "X_train_pca2 = pca2.transform(X_trainLAND)\n",
    "X_test_pca2 = pca2.transform(X_testLAND)\n",
    "X_final_pca2 = pca2.transform(X_finalLAND)\n",
    "\n",
    "SVM2 = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "SVM2 = SVM2.fit(X_train_pca2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-delaware",
   "metadata": {},
   "source": [
    "### Model 3 - XGBoost with Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "measured-biography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_class=7, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB1 = XGBClassifier(objective='multi:softprob', \n",
    "                         num_class= len(emotions), \n",
    "                         use_label_encoder=False,\n",
    "                         eval_metric='mlogloss')\n",
    "\n",
    "XGB1.fit(X_trainSVM, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-degree",
   "metadata": {},
   "source": [
    "### Model 4 - XGBoost with Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electoral-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_class=7, num_parallel_tree=1, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB2 = XGBClassifier(objective='multi:softprob', \n",
    "                         num_class= len(emotions), \n",
    "                         use_label_encoder=False,\n",
    "                         eval_metric='mlogloss')\n",
    "\n",
    "XGB2.fit(X_trainLAND, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-stretch",
   "metadata": {},
   "source": [
    "### Model 5 - VAE with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "twelve-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vae = np.expand_dims(X_test, -1).astype(\"float32\") / 255\n",
    "X_final_vae = np.expand_dims(X_final, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = keras.models.load_model(\"./gc-vae_model\")\n",
    "\n",
    "z_mean1, z_log_var1, z1 = vae.encoder.predict(X_test_vae)\n",
    "z_mean2, z_log_var2, z2 = vae.encoder.predict(X_final_vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-earth",
   "metadata": {},
   "source": [
    "## Ensemble Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-layout",
   "metadata": {},
   "source": [
    "### Soft Voting\n",
    "Here we take the probability distribution of the predictions and sum them over all predictions.  Then we take the argmax as the final predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dirty-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_vote(p1, p2, p3, p4):\n",
    "    total = p1 + p2 + p3 + p4\n",
    "    \n",
    "    return np.argmax(total, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entitled-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = SVM1.predict_proba(X_test_pca1)\n",
    "pred2 = SVM2.predict_proba(X_test_pca2)\n",
    "pred3 = XGB1.predict_proba(X_testSVM)\n",
    "pred4 = XGB2.predict_proba(X_testLAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pharmaceutical-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_pred = soft_vote(pred1, pred2, pred3, pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "monthly-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6322095291167457\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, sv_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-greene",
   "metadata": {},
   "source": [
    "### Hard Voting\n",
    "Here we take the majority vote from each models final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cross-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "      \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    "  \n",
    "    return num\n",
    "\n",
    "def maj_vote(p1, p2, p3, p4, p5):\n",
    "    final_pred = []\n",
    "    \n",
    "    for i in range(len(X_testLAND)):\n",
    "        tmp = [p1[i], p2[i], p3[i], p4[i], p5[i]]\n",
    "        final_pred.append(most_frequent(tmp))\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "curious-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1b = SVM1.predict(X_test_pca1)\n",
    "pred2b = SVM2.predict(X_test_pca2)\n",
    "pred3b = XGB1.predict(X_testSVM)\n",
    "pred4b = XGB2.predict(X_testLAND)\n",
    "pred5b = np.argmax(vae.predictor.predict(z_mean1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "genetic-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_pred = maj_vote(pred1b, pred2b, pred3b, pred4b, pred5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "irish-insert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.652549456673168\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, hv_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-grant",
   "metadata": {},
   "source": [
    "## Final Ensemble Prediction\n",
    "Here we use the private evaluation dataset and make our final prediction with our best ensemble (Hard Voting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "descending-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1final = SVM1.predict(X_final_pca1)\n",
    "pred2final = SVM2.predict(X_final_pca2)\n",
    "pred3final = XGB1.predict(X_finalSVM)\n",
    "pred4final = XGB2.predict(X_finalLAND)\n",
    "pred5final = np.argmax(vae.predictor.predict(z_mean2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "offensive-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = maj_vote(pred1final, pred2final, pred3final, pred4final, pred5final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ambient-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388966285873502\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_final, final_pred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
